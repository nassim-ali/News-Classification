{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline # pipeline to transform data\n",
    "from pyspark.sql import SparkSession # to initiate spark\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.feature import RegexTokenizer # tokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF # vectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover # to remove stop words\n",
    "from pyspark.sql.functions import concat_ws, col # to concatinate cols\n",
    "from pyspark.ml.classification import LogisticRegression # ml model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator # to evaluate the model\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DAGOUDI:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>news-classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1abc1c86720>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"news-classification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|Class Index|               Title|         Description|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          3|Wall St. Bears Cl...|Reuters - Short-s...|\n",
      "|          3|Carlyle Looks Tow...|Reuters - Private...|\n",
      "|          3|Oil and Economy C...|Reuters - Soaring...|\n",
      "|          3|Iraq Halts Oil Ex...|Reuters - Authori...|\n",
      "|          3|Oil prices soar t...|AFP - Tearaway wo...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/news-dataset.csv\", inferSchema=True, header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show 5 first rows with null values\n",
    "df.filter(df['Class Index'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming 'Class Index' col to 'label'\n",
    "df = df.withColumnRenamed('Class Index', 'label')\n",
    "\n",
    "# Add a new column 'Text' by concatinating 'Title' and 'Description'\n",
    "df = df.withColumn(\"Text\", concat_ws(\" \", \"Title\", 'Description'))\n",
    "\n",
    "# Remove old text columns\n",
    "df = df.select('label', 'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label='3', Text=\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                Text|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|    3|Wall St. Bears Cl...|[wall, st, bears,...|\n",
      "|    3|Carlyle Looks Tow...|[carlyle, looks, ...|\n",
      "|    3|Oil and Economy C...|[oil, and, econom...|\n",
      "|    3|Iraq Halts Oil Ex...|[iraq, halts, oil...|\n",
      "|    3|Oil prices soar t...|[oil, prices, soa...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert sentences to list of words\n",
    "tokenizer = RegexTokenizer(inputCol=\"Text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# adds a column 'words' to df after tokenization\n",
    "df = tokenizer.transform(df)\n",
    "\n",
    "df.select(['label','Text', 'words']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label='3', Text=\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", words=['wall', 'st', 'bears', 'claw', 'back', 'into', 'the', 'black', 'reuters', 'reuters', 'short', 'sellers', 'wall', 'street', 's', 'dwindling', 'band', 'of', 'ultra', 'cynics', 'are', 'seeing', 'green', 'again'], filtered=['wall', 'st', 'bears', 'claw', 'back', 'black', 'reuters', 'reuters', 'short', 'sellers', 'wall', 'street', 'dwindling', 'band', 'ultra', 'cynics', 'seeing', 'green'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to remove stop words like is, the, in, etc.\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "# adds a column 'filtered' to df without stopwords\n",
    "df = stopwords_remover.transform(df)\n",
    "\n",
    "df.select(['label','Text', 'words', 'filtered']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate term frequency in each article\n",
    "hashing_tf = HashingTF(inputCol=\"filtered\",\n",
    "                       outputCol=\"raw_features\", \n",
    "                       numFeatures=10000)\n",
    "\n",
    "# adds raw tf features to df\n",
    "featurized_data = hashing_tf.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label='3', Text=\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", words=['wall', 'st', 'bears', 'claw', 'back', 'into', 'the', 'black', 'reuters', 'reuters', 'short', 'sellers', 'wall', 'street', 's', 'dwindling', 'band', 'of', 'ultra', 'cynics', 'are', 'seeing', 'green', 'again'], filtered=['wall', 'st', 'bears', 'claw', 'back', 'black', 'reuters', 'reuters', 'short', 'sellers', 'wall', 'street', 'dwindling', 'band', 'ultra', 'cynics', 'seeing', 'green'], raw_features=SparseVector(10000, {551: 1.0, 662: 1.0, 1262: 1.0, 1449: 1.0, 1889: 1.0, 1948: 1.0, 2503: 1.0, 2826: 1.0, 3038: 1.0, 3684: 1.0, 4443: 1.0, 6404: 2.0, 8318: 1.0, 8430: 1.0, 8450: 2.0, 9430: 1.0}))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurized_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label='3', Text=\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", words=['wall', 'st', 'bears', 'claw', 'back', 'into', 'the', 'black', 'reuters', 'reuters', 'short', 'sellers', 'wall', 'street', 's', 'dwindling', 'band', 'of', 'ultra', 'cynics', 'are', 'seeing', 'green', 'again'], filtered=['wall', 'st', 'bears', 'claw', 'back', 'black', 'reuters', 'reuters', 'short', 'sellers', 'wall', 'street', 'dwindling', 'band', 'ultra', 'cynics', 'seeing', 'green'], features=SparseVector(10000, {551: 5.0673, 662: 6.0128, 1262: 4.8019, 1449: 5.9636, 1889: 6.9275, 1948: 4.9649, 2503: 7.6128, 2826: 5.9398, 3038: 4.6635, 3684: 4.3958, 4443: 5.7126, 6404: 9.1681, 8318: 8.034, 8430: 3.394, 8450: 4.6006, 9430: 6.4834}))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse document frequency\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "idf_vectorizer = idf.fit(featurized_data)\n",
    "\n",
    "# converting text to vectors\n",
    "rescaled_data = idf_vectorizer.transform(featurized_data)\n",
    "\n",
    "# top 20 rows\n",
    "rescaled_data.select(\"label\",'Text', 'words', 'filtered', \"features\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_data.filter(rescaled_data['label'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_data = rescaled_data.coalesce(1)\n",
    "(train, test) = rescaled_data.randomSplit([0.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.filter(train['label'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+--------+------------+--------+\n",
      "|label|Text|words|filtered|raw_features|features|\n",
      "+-----+----+-----+--------+------------+--------+\n",
      "+-----+----+-----+--------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_with_nulls = train.filter(train[\"label\"].isNull())\n",
    "train_with_nulls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 103720\n",
      "Test Dataset Count: 25813\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn(\"label\", train[\"label\"].cast(DoubleType()))\n",
    "test = test.withColumn(\"label\", test[\"label\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.filter(train['label'].isNull()).count()\n",
    "test.filter(test['label'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|                Text|               words|            filtered|        raw_features|            features|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1.0| #36;350,000 Siph...|[36, 350, 000, si...|[36, 350, 000, si...|(10000,[157,524,5...|(10000,[157,524,5...|\n",
      "|  1.0| #36;71M Judgment...|[36, 71m, judgmen...|[36, 71m, judgmen...|(10000,[531,633,1...|(10000,[531,633,1...|\n",
      "|  1.0| #39;70,000 Darfu...|[39, 70, 000, dar...|[39, 70, 000, dar...|(10000,[55,130,49...|(10000,[55,130,49...|\n",
      "|  1.0| #39;9-11 helper ...|[39, 9, 11, helpe...|[39, 9, 11, helpe...|(10000,[132,626,6...|(10000,[132,626,6...|\n",
      "|  1.0| #39;9/11 #39; PL...|[39, 9, 11, 39, p...|[39, 9, 11, 39, p...|(10000,[516,648,9...|(10000,[516,648,9...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove nulls from train\n",
    "train = train.na.drop()\n",
    "test = test.na.drop()\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+-----+\n",
      "|                Text|         probability|prediction|label|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "| #39;6-Way Talks ...|[8.73073472745514...|       1.0|  1.0|\n",
      "| #39;Arms photo r...|[1.07704484254278...|       1.0|  1.0|\n",
      "| #39;Batman #39; ...|[9.90718118605804...|       1.0|  1.0|\n",
      "| #39;Batman #39; ...|[6.06380393164773...|       1.0|  1.0|\n",
      "| #39;Batman dad i...|[1.11546818626372...|       1.0|  1.0|\n",
      "| #39;Bin Laden #3...|[5.36456157147562...|       1.0|  1.0|\n",
      "| #39;Black Widows...|[4.68598376297795...|       1.0|  1.0|\n",
      "| #39;I only wish ...|[9.03125373304269...|       1.0|  1.0|\n",
      "| #39;Jackal #39; ...|[1.02234890493050...|       1.0|  1.0|\n",
      "| #39;Mutilated bo...|[4.23915322208111...|       1.0|  1.0|\n",
      "| #39;Passion #39;...|[1.06412856826629...|       1.0|  1.0|\n",
      "| #39;Piano Teache...|[5.08437873723869...|       4.0|  1.0|\n",
      "| #39;Pirate #39; ...|[7.91468659029856...|       1.0|  1.0|\n",
      "| #39;Ransom deman...|[4.74360563188104...|       1.0|  1.0|\n",
      "| #39;Sharon is a ...|[5.22637255437663...|       1.0|  1.0|\n",
      "| #39;Small setbac...|[7.42920001904864...|       1.0|  1.0|\n",
      "| #39;Suicide #39;...|[1.13636023244262...|       1.0|  1.0|\n",
      "| #39;The blood is...|[1.32708490389377...|       2.0|  1.0|\n",
      "| #39;We #39;ll le...|[1.09628082630842...|       1.0|  1.0|\n",
      "| quot;Incendiary ...|[1.16110780913279...|       1.0|  1.0|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='features',\n",
    "                        labelCol='label',\n",
    "                        family=\"multinomial\",\n",
    "                        regParam=0.3,\n",
    "                        elasticNetParam=0,\n",
    "                        maxIter=50)\n",
    "\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "# get predictions for test set\n",
    "predictions = lrModel.transform(test)\n",
    "\n",
    "# show top 20 predictions\n",
    "predictions.select(\"Text\", 'probability','prediction', 'label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  1.0|\n",
      "|  2.0|\n",
      "|  3.0|\n",
      "|  4.0|\n",
      "|  5.0|\n",
      "|  6.0|\n",
      "|  7.0|\n",
      "|  8.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show unique value of label column of train\n",
    "train.select(\"label\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
